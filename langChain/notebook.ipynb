{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cbe228d",
   "metadata": {},
   "source": [
    "# LangChain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c63eec",
   "metadata": {},
   "source": [
    "# What is LangChain?\n",
    "\n",
    "LangChain is a powerful tool that can be used to work with Large Language Models (LLMs).\n",
    "\n",
    "LangChain is an intuitive open-source framework created to simplify the development of applications using large language models (LLMs), such as OpenAI or Hugging Face. This allows you to build dynamic, data-responsive applications that harness the most recent breakthroughs in natural language processing.\n",
    "\n",
    "LangChain streamlines the development of diverse applications, such as chatbots, Generative Question-Answering (GQA), and summarization. By “chaining” components from multiple modules, it allows for the creation of unique applications built around an LLM.\n",
    "\n",
    "\n",
    "At its core, LangChain is a framework built around LLMs. We can use it for chatbots, Generative Question-Answering (GQA), summarization, and much more.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5605756",
   "metadata": {},
   "source": [
    "The core idea of the library is that we can “chain” together different components to create more advanced use cases around LLMs. Chains may consist of multiple components from several modules:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7090fe2d",
   "metadata": {},
   "source": [
    "# What are the Modules of LangChain?\n",
    "\n",
    "These modules are the core abstractions which we view as the building blocks of any LLM-powered application.\n",
    "\n",
    "\n",
    "Prompt templates: Prompt templates are templates for different types of prompts. Like “chatbot” style templates, ELI5 question-answering, etc\n",
    "\n",
    "LLMs: Large language models like GPT-3, BLOOM, etc\n",
    "\n",
    "Agents: Agents use LLMs to decide what actions should be taken. Tools like web search or calculators can be used, and all are packaged into a logical loop of operations.\n",
    "\n",
    "Memory: Short-term memory, long-term memory. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96478cc2",
   "metadata": {},
   "source": [
    "https://langchain.readthedocs.io/en/latest/getting_started/getting_started.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a09216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "598a6441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I am a pasta lover and I would love to go to Italy, but I am not sure if\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, HuggingFaceHub, LLMChain\n",
    "\n",
    "# initialize HF LLM\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"bigscience/bloom\",\n",
    "    model_kwargs={\"temperature\":1e-10}\n",
    ")\n",
    "text = \"What are 5 vacation destinations for someone who likes to eat pasta?\"\n",
    "\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4b2b1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da0fae9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
